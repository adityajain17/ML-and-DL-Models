{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iris Data Set Attempt to Do Multi-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset=pd.read_csv('iris.data',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3            4\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x=dataset.iloc[:,0:4].values\n",
    "y=dataset.iloc[:,4].values\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "#For Encoding the Data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_y = LabelEncoder()\n",
    "y= labelencoder_y.fit_transform(y)\n",
    "print(labelencoder_y.classes_)\n",
    "print(labelencoder_y.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a6d0c46128>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_data=pd.DataFrame({'categories':y})\n",
    "y_data['categories'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Pre-Processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a6d0ca2390>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_data=pd.DataFrame({'categories':y_train})\n",
    "y_train_data['categories'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a6d0c3a710>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_data=pd.DataFrame({'categories':y_test})\n",
    "y_test_data['categories'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2 1 1 2 0 2 0 0]\n",
      "Confusion Matrix [[16  0  0]\n",
      " [ 0 17  1]\n",
      " [ 0  0 11]]\n",
      "Accuracy Score 97.77777777777777\n",
      "Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "   micro avg       0.98      0.98      0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0,solver='newton-cg',multi_class='multinomial')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred)\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix',cm)\n",
    "print('Accuracy Score',accuracy_score(y_test, y_pred)*100)\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "print('Classification Report \\n',classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[16  0  0]\n",
      " [ 0 17  1]\n",
      " [ 0  0 11]]\n",
      "Accuracy is  97.77777777777777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "   micro avg       0.98      0.98      0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN Classifier\n",
    "# Fitting K-NN to the Training set\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 3, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix',cm)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy is ',accuracy*100)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"uniform\", activation=\"softmax\", units=3)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "105/105 [==============================] - 0s 5ms/step - loss: 1.0910 - acc: 0.6000\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 1.0517 - acc: 0.7619\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.9526 - acc: 0.7238\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.7509 - acc: 0.7238\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 266us/step - loss: 0.5628 - acc: 0.7143\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.4614 - acc: 0.7143\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.4096 - acc: 0.7810\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 261us/step - loss: 0.3698 - acc: 0.8476\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 220us/step - loss: 0.3318 - acc: 0.8667\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.3103 - acc: 0.8667\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.2287 - acc: 0.900 - 0s 228us/step - loss: 0.2808 - acc: 0.8667\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.2629 - acc: 0.8762\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 249us/step - loss: 0.2449 - acc: 0.8952\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.2265 - acc: 0.8857\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 266us/step - loss: 0.2062 - acc: 0.8952\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 266us/step - loss: 0.1842 - acc: 0.9238\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.1660 - acc: 0.9429\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.1417 - acc: 0.9524\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 248us/step - loss: 0.1219 - acc: 0.9524\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 230us/step - loss: 0.1104 - acc: 0.9619\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 266us/step - loss: 0.0988 - acc: 0.9714\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0906 - acc: 0.9714\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0800 - acc: 0.9714\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0779 - acc: 0.9714\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0690 - acc: 0.9810\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0172 - acc: 1.000 - 0s 228us/step - loss: 0.0795 - acc: 0.9619\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 207us/step - loss: 0.0632 - acc: 0.9714\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0642 - acc: 0.9810\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0603 - acc: 0.9714\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0562 - acc: 0.9714\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.0551 - acc: 0.9810\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0543 - acc: 0.9810\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0512 - acc: 0.9714\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0513 - acc: 0.9714\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0499 - acc: 0.9714\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0503 - acc: 0.9714\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0455 - acc: 0.9810\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 130us/step - loss: 0.0452 - acc: 0.9905\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0446 - acc: 0.9905\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0456 - acc: 0.9905\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0435 - acc: 0.9810\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0430 - acc: 0.9905\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.0436 - acc: 0.9714\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0441 - acc: 0.9810\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0383 - acc: 0.9905\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0372 - acc: 0.9905\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0411 - acc: 1.000 - 0s 190us/step - loss: 0.0388 - acc: 0.9905\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.0961 - acc: 0.900 - 0s 173us/step - loss: 0.0400 - acc: 0.9810\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0371 - acc: 0.9905\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0346 - acc: 0.9905\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0401 - acc: 0.9810\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 266us/step - loss: 0.0392 - acc: 0.9905\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0321 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 266us/step - loss: 0.0353 - acc: 0.9810\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 266us/step - loss: 0.0331 - acc: 0.9905\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0322 - acc: 0.9905\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.0310 - acc: 0.9905\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0310 - acc: 0.9905\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0305 - acc: 0.9905\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0293 - acc: 0.9905\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 266us/step - loss: 0.0299 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0288 - acc: 0.9905\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0315 - acc: 0.9905\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0282 - acc: 0.9905\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0270 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0265 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0295 - acc: 0.9905\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0296 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 201us/step - loss: 0.0353 - acc: 0.9810\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0412 - acc: 0.9714\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0270 - acc: 0.9905\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0296 - acc: 0.9810\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0254 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0316 - acc: 0.9810\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0297 - acc: 0.9905\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 136us/step - loss: 0.0269 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0227 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0240 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0238 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0206 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 199us/step - loss: 0.0247 - acc: 0.9905\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 0s 114us/step - loss: 0.0210 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0260 - acc: 0.9810\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0238 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0207 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0213 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0183 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0195 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 222us/step - loss: 0.0213 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0171 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0173 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0199 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.0167 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a6d40c28d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aritifical Neural Network (ANN)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "model= Sequential()\n",
    "model.add(Dense(128, kernel_initializer='uniform',activation = 'relu', input_dim = 4))\n",
    "model.add(Dense(64, kernel_initializer='uniform',activation = 'relu'))\n",
    "model.add(Dense(output_dim = 3, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train, batch_size =10,nb_epoch = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2 1 1 2 0 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[16  0  0]\n",
      " [ 0 17  1]\n",
      " [ 0  0 11]]\n",
      "Accuracy Score 97.77777777777777\n",
      "Classification Report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "   micro avg       0.98      0.98      0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix',cm)\n",
    "print('Accuracy Score',accuracy_score(y_test, y_pred)*100)\n",
    "from sklearn.metrics import classification_report,f1_score\n",
    "print('Classification Report \\n',classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Iris-Ann 97.7 Accuracy.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "{}\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "#Now we will try ANN aftter One hot encoding it\n",
    "x=dataset.iloc[:,0:4].values\n",
    "y=dataset.iloc[:,4].values\n",
    "print(type(x))\n",
    "#For Encoding the Data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_y = LabelEncoder()\n",
    "y= labelencoder_y.fit_transform(y)\n",
    "print(labelencoder_y.classes_)\n",
    "print(labelencoder_y.get_params())\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 1)\n"
     ]
    }
   ],
   "source": [
    "#One-Hot Encoding y variable\n",
    "y=y.reshape(150,1)\n",
    "print(y.shape)\n",
    "onehotencoder = OneHotEncoder(categories='auto')\n",
    "y= onehotencoder.fit_transform(y).toarray()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"uniform\", activation=\"softmax\", units=3)`\n",
      "  if __name__ == '__main__':\n",
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "105/105 [==============================] - 1s 7ms/step - loss: 1.0936 - acc: 0.5619\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 161us/step - loss: 1.0778 - acc: 0.7429\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 1.0538 - acc: 0.7619\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 1.0103 - acc: 0.7619\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 465us/step - loss: 0.9541 - acc: 0.7524\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - 0s 275us/step - loss: 0.8867 - acc: 0.7524\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 332us/step - loss: 0.8077 - acc: 0.7333\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 256us/step - loss: 0.7345 - acc: 0.7238\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 256us/step - loss: 0.6671 - acc: 0.7143\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 276us/step - loss: 0.6131 - acc: 0.7143\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.5691 - acc: 0.7238\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 218us/step - loss: 0.5352 - acc: 0.7238\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 275us/step - loss: 0.5109 - acc: 0.7238\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.4883 - acc: 0.7333\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.4700 - acc: 0.7524\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 266us/step - loss: 0.4538 - acc: 0.7810\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.4390 - acc: 0.8000\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.4257 - acc: 0.8190\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 180us/step - loss: 0.4117 - acc: 0.8381\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.4002 - acc: 0.8476\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 199us/step - loss: 0.3878 - acc: 0.8476\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 180us/step - loss: 0.3772 - acc: 0.8571\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 313us/step - loss: 0.3661 - acc: 0.8667\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.3567 - acc: 0.8667\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 256us/step - loss: 0.3462 - acc: 0.8667\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 180us/step - loss: 0.3369 - acc: 0.8667\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 171us/step - loss: 0.3273 - acc: 0.8667\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 180us/step - loss: 0.3199 - acc: 0.8667\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.3120 - acc: 0.8667\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 209us/step - loss: 0.3049 - acc: 0.8667\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 275us/step - loss: 0.2968 - acc: 0.8762\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 304us/step - loss: 0.2908 - acc: 0.8762\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 266us/step - loss: 0.2830 - acc: 0.8762\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 209us/step - loss: 0.2764 - acc: 0.8762\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 256us/step - loss: 0.2706 - acc: 0.8762\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.2647 - acc: 0.8857\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.2584 - acc: 0.8857\n",
      "Epoch 38/100\n",
      "105/105 [==============================] - 0s 209us/step - loss: 0.2534 - acc: 0.8857\n",
      "Epoch 39/100\n",
      "105/105 [==============================] - 0s 266us/step - loss: 0.2462 - acc: 0.9048\n",
      "Epoch 40/100\n",
      "105/105 [==============================] - 0s 218us/step - loss: 0.2400 - acc: 0.9048\n",
      "Epoch 41/100\n",
      "105/105 [==============================] - 0s 218us/step - loss: 0.2342 - acc: 0.9143\n",
      "Epoch 42/100\n",
      "105/105 [==============================] - 0s 209us/step - loss: 0.2284 - acc: 0.9143\n",
      "Epoch 43/100\n",
      "105/105 [==============================] - 0s 342us/step - loss: 0.2234 - acc: 0.9238\n",
      "Epoch 44/100\n",
      "105/105 [==============================] - 0s 218us/step - loss: 0.2173 - acc: 0.9238\n",
      "Epoch 45/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.2119 - acc: 0.9238\n",
      "Epoch 46/100\n",
      "105/105 [==============================] - 0s 161us/step - loss: 0.2070 - acc: 0.9238\n",
      "Epoch 47/100\n",
      "105/105 [==============================] - 0s 199us/step - loss: 0.2014 - acc: 0.9238\n",
      "Epoch 48/100\n",
      "105/105 [==============================] - 0s 180us/step - loss: 0.1966 - acc: 0.9238\n",
      "Epoch 49/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.1912 - acc: 0.9238\n",
      "Epoch 50/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.1893 - acc: 0.9238\n",
      "Epoch 51/100\n",
      "105/105 [==============================] - 0s 399us/step - loss: 0.1824 - acc: 0.9333\n",
      "Epoch 52/100\n",
      "105/105 [==============================] - 0s 247us/step - loss: 0.1783 - acc: 0.9333\n",
      "Epoch 53/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.1740 - acc: 0.9333\n",
      "Epoch 54/100\n",
      "105/105 [==============================] - 0s 218us/step - loss: 0.1695 - acc: 0.9429\n",
      "Epoch 55/100\n",
      "105/105 [==============================] - 0s 180us/step - loss: 0.1660 - acc: 0.9429\n",
      "Epoch 56/100\n",
      "105/105 [==============================] - 0s 161us/step - loss: 0.1619 - acc: 0.9429\n",
      "Epoch 57/100\n",
      "105/105 [==============================] - 0s 199us/step - loss: 0.1578 - acc: 0.9429\n",
      "Epoch 58/100\n",
      "105/105 [==============================] - 0s 142us/step - loss: 0.1545 - acc: 0.9524\n",
      "Epoch 59/100\n",
      "105/105 [==============================] - 0s 161us/step - loss: 0.1512 - acc: 0.9429\n",
      "Epoch 60/100\n",
      "105/105 [==============================] - 0s 218us/step - loss: 0.1483 - acc: 0.9524\n",
      "Epoch 61/100\n",
      "105/105 [==============================] - 0s 199us/step - loss: 0.1447 - acc: 0.9619\n",
      "Epoch 62/100\n",
      "105/105 [==============================] - 0s 161us/step - loss: 0.1423 - acc: 0.9810\n",
      "Epoch 63/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.1382 - acc: 0.9810\n",
      "Epoch 64/100\n",
      "105/105 [==============================] - 0s 162us/step - loss: 0.1351 - acc: 0.9714\n",
      "Epoch 65/100\n",
      "105/105 [==============================] - 0s 161us/step - loss: 0.1325 - acc: 0.9714\n",
      "Epoch 66/100\n",
      "105/105 [==============================] - 0s 199us/step - loss: 0.1314 - acc: 0.9619\n",
      "Epoch 67/100\n",
      "105/105 [==============================] - 0s 180us/step - loss: 0.1275 - acc: 0.9619\n",
      "Epoch 68/100\n",
      "105/105 [==============================] - ETA: 0s - loss: 0.1027 - acc: 1.000 - 0s 161us/step - loss: 0.1252 - acc: 0.9714\n",
      "Epoch 69/100\n",
      "105/105 [==============================] - 0s 171us/step - loss: 0.1228 - acc: 0.9714\n",
      "Epoch 70/100\n",
      "105/105 [==============================] - 0s 180us/step - loss: 0.1206 - acc: 0.9714\n",
      "Epoch 71/100\n",
      "105/105 [==============================] - 0s 199us/step - loss: 0.1189 - acc: 0.9714\n",
      "Epoch 72/100\n",
      "105/105 [==============================] - 0s 266us/step - loss: 0.1169 - acc: 0.9714\n",
      "Epoch 73/100\n",
      "105/105 [==============================] - 0s 199us/step - loss: 0.1166 - acc: 0.9714\n",
      "Epoch 74/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.1125 - acc: 0.9714\n",
      "Epoch 75/100\n",
      "105/105 [==============================] - 0s 161us/step - loss: 0.1109 - acc: 0.9714\n",
      "Epoch 76/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.1093 - acc: 0.9714\n",
      "Epoch 77/100\n",
      "105/105 [==============================] - 0s 161us/step - loss: 0.1078 - acc: 0.9714\n",
      "Epoch 78/100\n",
      "105/105 [==============================] - 0s 190us/step - loss: 0.1066 - acc: 0.9714\n",
      "Epoch 79/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.1044 - acc: 0.9714\n",
      "Epoch 80/100\n",
      "105/105 [==============================] - 0s 171us/step - loss: 0.1035 - acc: 0.9714\n",
      "Epoch 81/100\n",
      "105/105 [==============================] - 0s 161us/step - loss: 0.1022 - acc: 0.9714\n",
      "Epoch 82/100\n",
      "105/105 [==============================] - 0s 209us/step - loss: 0.1003 - acc: 0.9714\n",
      "Epoch 83/100\n",
      "105/105 [==============================] - 0s 256us/step - loss: 0.0990 - acc: 0.9714\n",
      "Epoch 84/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0976 - acc: 0.9714\n",
      "Epoch 85/100\n",
      "105/105 [==============================] - 0s 142us/step - loss: 0.0968 - acc: 0.9714\n",
      "Epoch 86/100\n",
      "105/105 [==============================] - 0s 142us/step - loss: 0.0953 - acc: 0.9714\n",
      "Epoch 87/100\n",
      "105/105 [==============================] - 0s 152us/step - loss: 0.0942 - acc: 0.9714\n",
      "Epoch 88/100\n",
      "105/105 [==============================] - 0s 180us/step - loss: 0.0934 - acc: 0.9714\n",
      "Epoch 89/100\n",
      "105/105 [==============================] - 0s 294us/step - loss: 0.0922 - acc: 0.9714\n",
      "Epoch 90/100\n",
      "105/105 [==============================] - 0s 218us/step - loss: 0.0907 - acc: 0.9714\n",
      "Epoch 91/100\n",
      "105/105 [==============================] - 0s 218us/step - loss: 0.0898 - acc: 0.9714\n",
      "Epoch 92/100\n",
      "105/105 [==============================] - 0s 285us/step - loss: 0.0890 - acc: 0.9714\n",
      "Epoch 93/100\n",
      "105/105 [==============================] - 0s 199us/step - loss: 0.0881 - acc: 0.9714\n",
      "Epoch 94/100\n",
      "105/105 [==============================] - 0s 142us/step - loss: 0.0871 - acc: 0.9714\n",
      "Epoch 95/100\n",
      "105/105 [==============================] - 0s 256us/step - loss: 0.0865 - acc: 0.9714\n",
      "Epoch 96/100\n",
      "105/105 [==============================] - 0s 161us/step - loss: 0.0862 - acc: 0.9714\n",
      "Epoch 97/100\n",
      "105/105 [==============================] - 0s 237us/step - loss: 0.0846 - acc: 0.9714\n",
      "Epoch 98/100\n",
      "105/105 [==============================] - 0s 228us/step - loss: 0.0846 - acc: 0.9714\n",
      "Epoch 99/100\n",
      "105/105 [==============================] - 0s 218us/step - loss: 0.0831 - acc: 0.9714\n",
      "Epoch 100/100\n",
      "105/105 [==============================] - 0s 218us/step - loss: 0.0821 - acc: 0.9714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13e1a9a48d0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aritifical Neural Network (ANN)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the ANN\n",
    "model= Sequential()\n",
    "model.add(Dense(32, kernel_initializer='uniform',activation = 'relu', input_dim = 4))\n",
    "model.add(Dense(output_dim = 3, kernel_initializer = 'uniform', activation = 'softmax'))\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train, y_train, batch_size =10,nb_epoch = 100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
      " 2 1 1 2 0 2 0 0]\n",
      "[[1.1381799e-05 7.9482282e-03 9.9204034e-01]\n",
      " [4.4889218e-04 9.9147636e-01 8.0746636e-03]\n",
      " [9.9996269e-01 3.7336376e-05 3.7828418e-08]\n",
      " [1.5769598e-05 3.1107929e-02 9.6887636e-01]\n",
      " [9.9925584e-01 7.4358261e-04 5.4048542e-07]\n",
      " [1.0847480e-05 3.2911508e-03 9.9669802e-01]\n",
      " [9.9959153e-01 4.0816751e-04 4.1164114e-07]\n",
      " [5.0397352e-03 8.4861875e-01 1.4634147e-01]\n",
      " [1.2944156e-03 8.6446184e-01 1.3424376e-01]\n",
      " [4.5756083e-03 9.7172350e-01 2.3700872e-02]\n",
      " [2.6376278e-04 3.7111822e-01 6.2861800e-01]\n",
      " [1.1718893e-02 8.8170552e-01 1.0657563e-01]\n",
      " [2.9179861e-03 9.4781047e-01 4.9271461e-02]\n",
      " [1.7217094e-03 8.0034947e-01 1.9792877e-01]\n",
      " [3.7674885e-03 8.4855211e-01 1.4768031e-01]\n",
      " [9.9774325e-01 2.2557997e-03 9.3684156e-07]\n",
      " [4.2991303e-03 8.0116683e-01 1.9453397e-01]\n",
      " [2.5706198e-03 9.4468904e-01 5.2740391e-02]\n",
      " [9.9620759e-01 3.7896337e-03 2.7133754e-06]\n",
      " [9.9981862e-01 1.8114909e-04 2.4225969e-07]\n",
      " [1.4182289e-04 4.3247107e-02 9.5661110e-01]\n",
      " [8.9561027e-03 7.7799582e-01 2.1304798e-01]\n",
      " [9.9926180e-01 7.3741144e-04 8.6484658e-07]\n",
      " [9.9825114e-01 1.7473772e-03 1.4083759e-06]\n",
      " [5.0913048e-04 2.2437130e-01 7.7511960e-01]\n",
      " [9.9995673e-01 4.3325857e-05 5.5114384e-08]\n",
      " [9.9969554e-01 3.0377350e-04 7.2855590e-07]\n",
      " [5.1880637e-03 9.5975995e-01 3.5052028e-02]\n",
      " [6.3685332e-03 9.8582155e-01 7.8099072e-03]\n",
      " [9.9872452e-01 1.2737142e-03 1.7617431e-06]\n",
      " [4.6955587e-04 1.1174788e-01 8.8778257e-01]\n",
      " [1.0335466e-02 7.5401086e-01 2.3565376e-01]\n",
      " [9.9923897e-01 7.6057279e-04 4.8037049e-07]\n",
      " [1.2155289e-03 2.2731790e-01 7.7146655e-01]\n",
      " [6.5120780e-06 7.7390098e-03 9.9225450e-01]\n",
      " [6.7791510e-03 9.1821820e-01 7.5002596e-02]\n",
      " [9.9900812e-01 9.9117088e-04 7.0150031e-07]\n",
      " [4.8511231e-04 3.1463036e-01 6.8488449e-01]\n",
      " [9.5161796e-03 8.8317502e-01 1.0730881e-01]\n",
      " [2.6555101e-03 9.7761130e-01 1.9733239e-02]\n",
      " [3.5621208e-05 2.0503759e-02 9.7946060e-01]\n",
      " [9.9928576e-01 7.1369938e-04 5.4090384e-07]\n",
      " [4.8182559e-05 1.7037932e-02 9.8291391e-01]\n",
      " [9.9887460e-01 1.1221757e-03 3.2073879e-06]\n",
      " [9.9954152e-01 4.5823742e-04 2.8740979e-07]]\n",
      "(45, 3)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "print(y_pred)\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n",
    "print(y_pred.shape)\n",
    "#You can't use sklearn.metrics when y_pred is more than 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
